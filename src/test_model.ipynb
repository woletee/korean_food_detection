{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading or testing the model: 'utf-8' codec can't decode byte 0xd5 in position 36: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def preprocess_image(file_path, target_size=(224, 224)):\n",
    "    img = load_img(file_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    return img_array\n",
    "\n",
    "def get_class_names():\n",
    "    return [\n",
    "        \"bibimbap\", \"bulgogi\", \"godeungeogui\", \"jjambbong\", \"ramyun\",\n",
    "        \"yangnyumchicken\", \"duinjangjjigae\", \"gamjatang\", \"gimbap\", \"jeyukbokkeum\",\n",
    "        \"jjajangmyeon\", \"kalguksu\", \"kimchijjigae\", \"mandu\", \"pajeon\",\n",
    "        \"samgyetang\", \"samgyeopsal\", \"sundaegukbap\", \"tteokbokki\", \"tteokguk\"\n",
    "    ]\n",
    "\n",
    "# Path to the saved model\n",
    "model_path = 'C:/Users/dslab/OneDrive - GIST/바탕 화면/Desktop Backup/ReacApp/src/foods_saved_model.h5'\n",
    "\n",
    "try:\n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Model loaded successfully from {model_path}\")\n",
    "    \n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Test the model with a sample image\n",
    "    test_image_path = 'C:/Users/dslab/OneDrive - GIST/바탕 화면/Desktop Backup/ReacApp/k1.jpg'  # Update this path to an actual image path\n",
    "    img_array = preprocess_image(test_image_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    class_names = get_class_names()\n",
    "    predicted_label = class_names[predicted_class]\n",
    "    print(f'Predicted class: {predicted_label}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or testing the model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 25s 441ms/step - loss: 1.3586 - accuracy: 0.5842 - val_loss: 0.8007 - val_accuracy: 0.7678\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 24s 447ms/step - loss: 0.4883 - accuracy: 0.8428 - val_loss: 0.7265 - val_accuracy: 0.7891\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 24s 457ms/step - loss: 0.3130 - accuracy: 0.8956 - val_loss: 0.6590 - val_accuracy: 0.7891\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 24s 450ms/step - loss: 0.2206 - accuracy: 0.9318 - val_loss: 0.6670 - val_accuracy: 0.8081\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 24s 447ms/step - loss: 0.1471 - accuracy: 0.9531 - val_loss: 0.6502 - val_accuracy: 0.8057\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 24s 448ms/step - loss: 0.1191 - accuracy: 0.9614 - val_loss: 0.6439 - val_accuracy: 0.8270\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 24s 449ms/step - loss: 0.1013 - accuracy: 0.9692 - val_loss: 0.8352 - val_accuracy: 0.7701\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 24s 449ms/step - loss: 0.1096 - accuracy: 0.9674 - val_loss: 0.6182 - val_accuracy: 0.8318\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 24s 444ms/step - loss: 0.0578 - accuracy: 0.9852 - val_loss: 0.6627 - val_accuracy: 0.8294\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 24s 445ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.7047 - val_accuracy: 0.8033\n",
      "14/14 [==============================] - 4s 300ms/step - loss: 0.7047 - accuracy: 0.8033\n",
      "Validation Accuracy: 80.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define paths\n",
    "train_images_dir = 'C:/Users/dslab/Downloads/train-20240522T054636Z-001/train/images'\n",
    "labels_dir = 'C:/Users/dslab/Downloads/train-20240522T054636Z-001/train/labels'\n",
    "\n",
    "# Function to create a dictionary of image paths and their corresponding labels\n",
    "def create_labels_dict(labels_dir):\n",
    "    labels_dict = {}\n",
    "    for label_file in os.listdir(labels_dir):\n",
    "        if label_file.endswith('.txt'):  # Assuming label files are .txt\n",
    "            file_path = os.path.join(labels_dir, label_file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    class_id = int(parts[0])  # Assuming first part is the class_id\n",
    "                    image_name = os.path.splitext(label_file)[0] + '.jpg'  # Assuming image extension is .jpg\n",
    "                    labels_dict[image_name] = class_id\n",
    "    return labels_dict\n",
    "\n",
    "# Create labels dictionary\n",
    "labels_dict = create_labels_dict(labels_dir)\n",
    "\n",
    "# Get unique labels\n",
    "unique_labels = list(set(labels_dict.values()))\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "\n",
    "# Image data generator for preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Use 20% of data for validation\n",
    ")\n",
    "\n",
    "# Helper function to load images and labels\n",
    "def load_data(image_dir, labels_dict, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_name, class_id in labels_dict.items():\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        if os.path.exists(image_path):\n",
    "            img = load_img(image_path, target_size=target_size)\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(class_id)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load images and labels\n",
    "images, labels = load_data(train_images_dir, labels_dict)\n",
    "\n",
    "# Split into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(unique_labels))\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=len(unique_labels))\n",
    "\n",
    "# Define the model\n",
    "# Load pre-trained MobileNetV2 model without the top layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(unique_labels), activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Image data generator for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Image data generator for validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
    "validation_generator = val_datagen.flow(x_val, y_val, batch_size=32)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "model.save('food_saved_model.h5')\n",
    "# Assuming `model` is your trained model\n",
    "model.save('foods_saved_model.h5')\n",
    "\n",
    "# Making Predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Define class names\n",
    "class_names = [\n",
    "    \"bibimbap\", \"bulgogi\", \"godeungeogui\", \"jjambbong\", \"ramyun\",\n",
    "    \"yangnyumchicken\", \"duinjangjjigae\", \"gamjatang\", \"gimbap\", \"jeyukbokkeum\",\n",
    "    \"jjajangmyeon\", \"kalguksu\", \"kimchijjigae\", \"mandu\", \"pajeon\",\n",
    "    \"samgyetang\", \"samgyeopsal\", \"sundaegukbap\", \"tteokbokki\", \"tteokguk\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:/Users/dslab/OneDrive - GIST/바탕 화면/Desktop Backup/ReacApp/src/saved_model.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Remove the existing saved model directory if it exists\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(saved_model_dir):\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Save the model in TensorFlow SavedModel format (as a directory)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39msave(saved_model_dir)\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\shutil.py:740\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\shutil.py:599\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    597\u001b[0m         entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(scandir_it)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 599\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m     entries \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries:\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\shutil.py:596\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rmtree_unsafe\u001b[39m(path, onerror):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m scandir_it:\n\u001b[0;32m    597\u001b[0m             entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(scandir_it)\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:/Users/dslab/OneDrive - GIST/바탕 화면/Desktop Backup/ReacApp/src/saved_model.h5'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a simple model for demonstration purposes\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(784,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Paths for the saved models\n",
    "saved_model_dir = 'C:/Users/dslab/OneDrive - GIST/바탕 화면/Desktop Backup/ReacApp/src/saved_model.h5'\n",
    "hdf5_model_path = 'model.h5'\n",
    "\n",
    "# Remove the existing saved model directory if it exists\n",
    "if os.path.exists(saved_model_dir):\n",
    "    shutil.rmtree(saved_model_dir)\n",
    "\n",
    "# Save the model in TensorFlow SavedModel format (as a directory)\n",
    "model.save(saved_model_dir)\n",
    "\n",
    "# Save the model in HDF5 format (as a single file)\n",
    "model.save(hdf5_model_path)\n",
    "\n",
    "# Loading the model in TensorFlow SavedModel format\n",
    "model_saved = tf.keras.models.load_model(saved_model_dir)\n",
    "print(\"Model loaded from SavedModel format\")\n",
    "model_saved.summary()\n",
    "\n",
    "# Loading the model in HDF5 format\n",
    "model_h5 = tf.keras.models.load_model(hdf5_model_path)\n",
    "print(\"Model loaded from HDF5 format\")\n",
    "model_h5.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
